{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhipraay/CVI_Projects_PS_22_23/blob/main/DL_PS_22_23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjbIgGuAOz5I"
      },
      "source": [
        "# Image Classification Using CNN\n",
        "#### By The Computer Vision and Intelligence Club (CVI) - IIT Madras\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sh-27b_jXK8"
      },
      "source": [
        "This aim of this Problem Statement is to introduce Deep Learning, which is one of the most used techniques for Computer Vision Application. \n",
        "Before beginning go thorugh the following articles:\n",
        "1. https://www.nature.com/articles/nature14539 : It is fairly easy to follow and provides an excellent overview of the field. (You will need to login with smail to download the pdf.) \n",
        "\n",
        "2. http://deeplearning.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/ : A short introduction to Multi-layer perceptrons.\n",
        "\n",
        "3. https://cs231n.github.io/convolutional-networks/ : Introduction to Convolutional Neural Networks. CNNs are generally used for computer vision problems.\n",
        "\n",
        "\n",
        "This introduction should be sufficient to get you started with this problem statement. If after going through the PS, you guys are interested in further exploring the field, I would suggest the following resources:\n",
        "1. http://cs231n.stanford.edu/ : Online course by Stanford.\n",
        "2. http://introtodeeplearning.com/: Video Lectures from MIT\n",
        "3. https://www.deeplearningbook.org/: Most popular book on Deep Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5cK9DWljhoo"
      },
      "source": [
        "We'll build a CNN using Pytorch to use it to classify thousands of pictures in 6 different categories.\n",
        "\n",
        "Sounds like a huge task, but do not worry! Remember to use Google freely to search for any doubts, errors or documentation. This assignment is not only to check your DL skills, but also how you can step up to learn new things on the go using publicly available sources.\n",
        "\n",
        "Ideally at the end, we expect that you understand the code in EVERY cell\n",
        "\n",
        "Enter your code between areas surrounded by the following comment design\n",
        "######### YOUR CODE HERE #########\n",
        "\n",
        "\n",
        "################################\n",
        "\n",
        "[Link For The Dataset](https://drive.google.com/uc?id=1Qc66kVqetwJIK7cKXnXxbPJy6gnpRSRI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyr9xCP9jyne"
      },
      "source": [
        "The aim of this get you all familiarized with Deep Learning in TensorFlow, a very popular Deep Learning Library (or in general GPU computation library).\n",
        "\n",
        "Some of the dataloading and preprocessing work has been done, and you guys are expected to fill-in code where you are asked to. \n",
        "\n",
        "Before diving into the code ensure that you copy the notebook to your drive (See the option in File Tab) and that the Runtime Type is set to GPU (Runtime tab -> Change runtime type). To see the importance of GPU in deep learning see [this](https://course.fast.ai/gpu_tutorial.html) short article.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clXXy5KnAjXB"
      },
      "source": [
        "\n",
        "\n",
        "First we import the necessary libraries. We recommend that you check out what these libraries are if they seem unfamiliar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koTFeclBOz5M",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "import os\n",
        "import glob as gb\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5GqcwrySwkP"
      },
      "source": [
        "# Downloading the Data and Extracting it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdEwBoAkPjh6"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=1Qc66kVqetwJIK7cKXnXxbPJy6gnpRSRI\n",
        "!unzip The_Data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS7eV5L3Oz5O"
      },
      "source": [
        "Now define the paths to the train test and pred folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tm9b0ZlDOz5P",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "######### YOUR CODE HERE #########\n",
        "trainpath = './RandomFolder/RandomSubFolder/TheFolderIWant'\n",
        "testpath = ''\n",
        "predpath = ''\n",
        "\n",
        "##################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_YCU8RoOz5Q"
      },
      "source": [
        "# Data Loading\n",
        "\n",
        "\n",
        "Now let's first check the Train folder to have a look to its content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8aHEePNOz5R",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for folder in  os.listdir(trainpath + 'seg_train') : \n",
        "    files = gb.glob(pathname= str( trainpath +'seg_train//' + folder + '/*.jpg'))\n",
        "    print(f'For training data , found {len(files)} in folder {folder}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72M3TdcqOz5S"
      },
      "source": [
        "Ok, how about the test folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSgCHYJcOz5S",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for folder in  os.listdir(testpath +'seg_test') : \n",
        "    files = gb.glob(pathname= str( testpath +'seg_test//' + folder + '/*.jpg'))\n",
        "    print(f'For testing data , found {len(files)} in folder {folder}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qokkhkCsOz5T"
      },
      "source": [
        "_____\n",
        "Now for prediction folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcjoyFzJOz5U",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "files = gb.glob(pathname= str(predpath +'seg_pred/*.jpg'))\n",
        "print(f'For Prediction data , found {len(files)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMMhtR59Oz5V"
      },
      "source": [
        "_____\n",
        "\n",
        "# Checking Images\n",
        "\n",
        "Now we need to check the images sizes , to know how they look like\n",
        "\n",
        "Since we have 6 categories , we first need to create a dictionary with their names & indices. This is known as integer encoding. Also create a function to get the code back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9H1Ds8pOz5W",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "code_to_num = {'buildings':0 ,'forest':1, 'glacier':2, 'mountain':3, 'sea':4, 'street':5}\n",
        "num_to_code = {0:'buildings' ,1:'forest', 2:'glacier', 3:'mountain', 4:'sea', 5:'street'}\n",
        "\n",
        "def get_code(n) : \n",
        "    if n in num_to_code:\n",
        "        return num_to_code[n]    \n",
        "\n",
        "def get_num(c):\n",
        "    if c in code_to_num:\n",
        "        return code_to_num[c] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLFrYewDOz5X"
      },
      "source": [
        "Now how about the images sizes in train folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfj3TlLQOz5X",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "size = []\n",
        "for folder in  os.listdir(trainpath +'seg_train') : \n",
        "    files = gb.glob(pathname= str( trainpath +'seg_train//' + folder + '/*.jpg'))\n",
        "    for file in files: \n",
        "        image = plt.imread(file)\n",
        "        size.append(image.shape)\n",
        "pd.Series(size).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swsdbbnkOz5Y"
      },
      "source": [
        "______\n",
        "\n",
        "Ok, almost all of them are (150,150,3), how about test images ? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY5VwvEPOz5Z",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "size = []\n",
        "for folder in  os.listdir(testpath +'seg_test') : \n",
        "    files = gb.glob(pathname= str( testpath +'seg_test//' + folder + '/*.jpg'))\n",
        "    for file in files: \n",
        "        image = plt.imread(file)\n",
        "        size.append(image.shape)\n",
        "pd.Series(size).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmGxfbuPOz5a"
      },
      "source": [
        "Almost same ratios  \n",
        "Now to prediction images "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUPmrwtZOz5a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "size = []\n",
        "files = gb.glob(pathname= str(predpath +'seg_pred/*.jpg'))\n",
        "for file in files: \n",
        "    image = plt.imread(file)\n",
        "    size.append(image.shape)\n",
        "pd.Series(size).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAWdiCW7Oz5b"
      },
      "source": [
        "Ok , since almost all of pictures are (150,150,3) , we can use all pictures in our model, after resizing it to a particular size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfMstFqyOz5c"
      },
      "source": [
        "# Reading Images\n",
        "\n",
        "Now it's time to read all images & convert it into arrays\n",
        "\n",
        "First we'll create a variable s , which refer to size , so we can change it easily \n",
        "\n",
        "Let's use now size = 100 , so it will be suitable amount to contain accuracy without losing so much time in training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0B2kG3jOz5d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "s = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvTebpaJOz5e"
      },
      "source": [
        "Now to read all pictues in six categories in training folder, and use OpenCV to resize it. And not to forget assigning the y value from the predefined function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUQ37lzjOz5e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "X_train_image = []   # contains the image with data type unit8 for visualisation\n",
        "X_train = []         # converted to tensor and normalised for training\n",
        "y_train = []\n",
        "for folder in  os.listdir(trainpath +'seg_train') : \n",
        "    files = gb.glob(pathname= str( trainpath +'seg_train//' + folder + '/*.jpg'))\n",
        "    for file in files: \n",
        "        image = cv2.imread(file)\n",
        "        image_array = cv2.resize(image , (s,s))\n",
        "        image = (torch.tensor(np.array(cv2.resize(image,(s,s)))).permute(2,0,1) )/255\n",
        "        \n",
        "        X_train_image.append(image_array)\n",
        "        X_train.append(image)\n",
        "        y_train.append(get_num(folder))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP-KMcOqOz5f"
      },
      "source": [
        "Great , now how many items in X_train "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2EXBm6xOz5g",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(f'we have {len(X_train)} items in X_train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiM_OtVZOz5h"
      },
      "source": [
        "Also we have have a look to random pictures in X_train , and to adjust their title using the y value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmP7O6-ZOz5h",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "for n , i in enumerate(list(np.random.randint(0,len(X_train),36))) : \n",
        "    plt.subplot(6,6,n+1)\n",
        "    plt.imshow(X_train_image[i])   \n",
        "    plt.axis('off')\n",
        "    plt.title(get_code(y_train[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLuUP5V_Oz5i"
      },
      "source": [
        "Great , now to repeat same steps exactly in test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZWqIDeQOz5j",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X_test_image = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "for folder in  os.listdir(testpath +'seg_test') : \n",
        "    files = gb.glob(pathname= str(testpath + 'seg_test//' + folder + '/*.jpg'))\n",
        "    for file in files: \n",
        "        image = cv2.imread(file)\n",
        "        image_array = cv2.resize(image , (s,s))\n",
        "        image = (torch.tensor(np.array(cv2.resize(image,(128,128)))).permute(2,0,1) )/255\n",
        "        X_test.append(image)         \n",
        "        X_test_image.append(list(image_array))\n",
        "        y_test.append(get_num(folder))\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDJ8B8UUOz5k",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(f'we have {len(X_test)} items in X_test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZ5g8l6dOz5l",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "for n , i in enumerate(list(np.random.randint(0,len(X_test_image),36))) : \n",
        "    plt.subplot(6,6,n+1)\n",
        "    plt.imshow(X_test_image[i])    \n",
        "    plt.axis('off')\n",
        "    plt.title(get_code(y_test[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKaTakNMOz5l"
      },
      "source": [
        "Also with Prediction data , without having title ofcourse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPqTXjPJOz5m",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X_pred_image = []\n",
        "X_pred = []\n",
        "files = gb.glob(pathname= str(predpath + 'seg_pred/*.jpg'))\n",
        "for file in files: \n",
        "    image = cv2.imread(file)\n",
        "    image_array = cv2.resize(image , (s,s))\n",
        "    image = (torch.tensor(np.array(cv2.resize(image,(128,128)))).permute(2,0,1) )/255\n",
        "    X_pred.append(image)\n",
        "    X_pred_image.append(list(image_array))    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwpbsMcZOz5n",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(f'we have {len(X_pred)} items in X_pred')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K17f6tciOz5n",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "for n , i in enumerate(list(np.random.randint(0,len(X_pred_image),36))) : \n",
        "    plt.subplot(6,6,n+1)\n",
        "    plt.imshow(X_pred_image[i])    \n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddzrCyb6Oz5o"
      },
      "source": [
        "________\n",
        "\n",
        "# Building The Model \n",
        "\n",
        "Now we need to build the model to train our data\n",
        "\n",
        "converting the tensors to dataloaders\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ok8jjDkkOz5o",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# first make a trainset and then the trainloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LneEhG4Vo1j"
      },
      "outputs": [],
      "source": [
        "# first make a testset and then the testloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FlkOtQgVotr"
      },
      "outputs": [],
      "source": [
        "# first make a predset and then the predloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG1kv36fOz5p"
      },
      "source": [
        "Now to build the CNN model using pytorch, using Conv2D layers , MaxPooling & Dropouts and Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agD8NVLsOz5q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "############### YOUR CODE HERE  ####################\n",
        "class Model(nn.Module):\n",
        "      def __init__(self):\n",
        "        super(Model, self).__init__()  \n",
        "\n",
        "      def forward(self, x): # x is the input image\n",
        "\n",
        "        return \n",
        "\n",
        "####################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru7oeFpjOz5s"
      },
      "source": [
        "So how the model looks like ? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-jFr_rLOz5s",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model = Model()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmWJUrYLOz5t"
      },
      "source": [
        "Now to train the model , lets use 50 epochs now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaPiCt74Oz5t",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "############### YOUR CODE HERE  ####################\n",
        "\n",
        "epochs = 50\n",
        "learning_rate = ?\n",
        "\n",
        "criterion = ?\n",
        "\n",
        "\n",
        "optimizer = ?\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "def accuracy(y_pred, y):\n",
        "    _, predicted = torch.max(y_pred.data, 1)\n",
        "    total = y.size(0)\n",
        "    correct = (predicted == y).sum().item()\n",
        "    return correct/total\n",
        "\n",
        "def train(model, dataset, optimizer, criterion,epoch):\n",
        "\n",
        "    model.train()\n",
        "    train_loss=[]\n",
        "    train_acc=[]\n",
        "    for batch_idx,(data,target) in enumerate(dataset):\n",
        "      \n",
        "        output=model(data)\n",
        "        optimizer.zero_grad()\n",
        "        loss=criterion(output,target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        acc = accuracy(output, target)\n",
        "        train_acc.append(acc)\n",
        "        train_loss.append(loss.item())\n",
        "        print('\\repoch:{}({:.0f}%)\\tloss:{:.3f}\\ttrain_accuracy:{:.2f}%'.format(epoch+1,100*batch_idx/len(dataset),\n",
        "        np.mean(train_loss),100*np.mean(train_acc)),end='')\n",
        "    print()\n",
        "\n",
        "def eval(model, dataset, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    val_acc=[]\n",
        "    for batch_idx,(data,target) in enumerate(dataset):\n",
        "        output=model(data)\n",
        "        acc = accuracy(output, target)\n",
        "        val_acc.append(acc)\n",
        "    print('val_accuracy:{:.2f}%'.format(100*np.mean(val_acc))) \n",
        "    return np.mean(val_acc)\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "      start_time = time.monotonic()\n",
        "      train(model, trainloader, optimizer, criterion,epoch)\n",
        "      eval_accuracy = eval(model, testloader, criterion)\n",
        "      end_time = time.monotonic()\n",
        "      epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "      print(\"TIME TAKEN FOR THE EPOCH: {} mins and {} seconds\\n\".format(epoch_mins, epoch_secs))\n",
        "print(\"OVERALL TRAINING COMPLETE\")      \n",
        "\n",
        "\n",
        "####################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIRWfNXMOz5u"
      },
      "source": [
        "How is the final loss & accuracy?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ktc2gK2Oz5u",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "eval(model, testloader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbIAOg4iOz5w"
      },
      "source": [
        "\n",
        "_______\n",
        "\n",
        "Now to predict X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBbFk7vrOz5w",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y_pred = []\n",
        "for  data, target in testloader:\n",
        "  data, target = data.to(device), target.to(device)\n",
        "  output = model(data.double())\n",
        "  _, preds = torch.max(output.data, 1)\n",
        "  preds = preds.cpu().numpy()\n",
        "  y_pred.append(preds)\n",
        "y_pred = np.array(y_pred)\n",
        "y_pred = np.concatenate( y_pred, axis=0 )\n",
        "print('Prediction Shape is {}'.format(y_pred.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3FHZ9lrOz5x"
      },
      "source": [
        "\n",
        "Now it's time to predict X_Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCJihtl5Oz5x",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y_result = []\n",
        "for data in predloader:\n",
        "  data = data.to(device)\n",
        "  output = model(data.double())\n",
        "  _, preds = torch.max(output.data, 1)\n",
        "  preds = preds.cpu().numpy()\n",
        "  y_result.append(preds)\n",
        "y_result = np.array(y_result)\n",
        "y_result = np.concatenate( y_result, axis=0 )  \n",
        "print('Prediction Shape is {}'.format(y_result.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB2o63d6Oz5y"
      },
      "source": [
        "And show random redicted pictures & its predicting category\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6y9PL4xOz5y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "for n , i in enumerate(list(np.random.randint(0,len(X_pred),36))) : \n",
        "    plt.subplot(6,6,n+1)\n",
        "    plt.imshow(X_pred[i])    \n",
        "    plt.axis('off')\n",
        "    plt.title(get_code(np.argmax(y_result[i])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FU3fSMkabPRb"
      },
      "outputs": [],
      "source": [
        "#### BONUS POINTS FOR SOME TRANSFER LEARNING APPROACH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjxWBxHEkU1j"
      },
      "source": [
        "[Basics Of Transfer Learning](https://machinelearningmastery.com/transfer-learning-for-deep-learning/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "DL_PS_22_23.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
